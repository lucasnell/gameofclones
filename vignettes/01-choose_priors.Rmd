---
title: "Choosing priors"
author: "Lucas A. Nell"
date: "2018-07-04"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Choosing priors}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "svglite", 
  fig.width = 6,
  fig.height = 4,
  echo = FALSE
)
# knitr::opts_knit$set(root.dir = normalizePath(".."))
options(tibble.print_min = 4L, tibble.print_max = 4L)
```
```{r source_Rprofile, echo = FALSE}
if (!isTRUE(getOption('knitr.in.progress'))) source(".Rprofile")
```



```{r library_pkgs, warning=FALSE}
set.seed(196534)
suppressPackageStartupMessages({
    library(clonewars)
})
bayesplot::color_scheme_set("viridis")
dlnorm_ <- function(x, location, scale) {
    dlnorm(x, meanlog = location, sdlog = scale)
}
# To store priors:
theta <- numeric(12)
# ggplot theme:
theme_set(theme_classic() %+replace%
              theme(strip.background = element_blank(),
                    strip.text = element_text(size = 11),
                    legend.background = element_blank(),
                    plot.title = element_text(size = 14, hjust = 0)))
```


This document outlines how I created my prior values.
See `vignette("Model description")` for my model description.
In general, my goal is to create weakly informative prior distributions:

> We characterize a prior distribution as *weakly informative* if it is proper but
> is set up so that the information it does provide is intentionally weaker
> than whatever actual prior knowledge is available. (p 55, Gelman et al. 2014)

* Gelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2014.
  *Bayesian Data Analysis*. Third edition. CRC Press, Boca Raton, FL, USA.



## Notes

__On truncated distributions\:__

Below, `T[0,]` indicates that a distribution is truncated to be above zero.


__On hyperparameters\:__

Prior information is stored as a vector of hyperparameters $\mathbf{\Theta}$,
indexed for each hyperparameter as $\theta_i$ for position $i$.




## Process error priors

```{r define_process_priors}
# Below are meanlog and sdlog parameters for the log-normal distribution
# that generates values for the process error standard deviation
theta[1] <- 0.15
theta[2] <- 1
```


$\sigma_\varepsilon$ was sampled as $\sim \text{N}(\theta_1, \theta_2^2) \texttt{T[0,]}$.
Based on simulations, a $\sigma_\varepsilon$ of 1 would be very high---so high as to
be not realistically possible.
Values of ~ 0.15 seemed to result in simulations matching some preliminary experimental
results we've seen in the lab.
Below, `r sprintf('"theta[1] %.2f"', theta[1])` is simulated data with process
error set to $`r theta[1]`$, "theta[1] 1" has process error set to $1.0$.
The others are the preliminary data.

```{r load_prior}
load_prior_data() %>% 
    filter(!is.na(line)) %>% 
    add_row(line = paste0("theta[1] ", theta[1]), rep = rep(1:5, each=16),
            date = rep(5:20,5),
            X = sim_lines(R = 0.2, alpha = 1/1000, n_reps = 5, nobs_ts = rep(16, 5), 
                          sigma_process = theta[1]) %>% 
                as.numeric()) %>% 
    add_row(line = "theta[1] 1", rep = rep(1:5, each=16), date = rep(5:20,5),
            X = sim_lines(R = 0.2, alpha = 1/1000, n_reps = 5, nobs_ts = rep(16, 5), 
                          sigma_process = 1) %>% 
                as.numeric()) %>% 
    mutate(rep = factor(rep)) %>% 
    ggplot(aes(date, X)) +
    geom_line(aes(color = rep)) +
    facet_wrap(~ line) +
    scale_color_brewer(palette = "Dark2", guide = FALSE)
```


To sample $\sigma_\varepsilon$,
I chose a mean (parameter $\theta_1$) of $`r theta[1]`$ and SD ($\theta_2$ parameter)
of $`r theta[2]`$.
I chose these values because they result in low densities at values close to 1.

```{r process_error_plot}
compare_priors("normal", theta[1], theta[2], xlim = c(0, theta[1] + 2)) +
    geom_vline(xintercept = theta[1]) +
    ggtitle(expression(sigma[epsilon] %~% plain("N")(theta[1] * "," ~ theta[2]))) +
    coord_cartesian(ylim = c(0, 0.4 / theta[2])) +
    NULL
```






## Growth rate priors

Log-transformed growth rates ($\log(r)$) were sampled as a function of an among-line
mean ($\rho \sim \text{N} ( \theta_3, \theta_4^{~2} )$) and
SD ($\sigma_\rho \sim \text{N} ( \theta_5, \theta_6^{~2} ) \texttt{T[0,]}$).

For growth-rate prior information, I first used data sent to me from A.R. Ives
related to this paper:

* Meisner, M. H., J. P. Harmon, and A. R. Ives. 2014. Temperature effects on
  long-term population dynamics in a parasitoid–host system.
  *Ecological Monographs* __84__:457–476.

The dataset had low and high estimates for fecundity, juvenile survival, and adult
survival.
I created two Leslie matrices, one with all of the high estimates and another
with all of the lower estimates.
For each of these Leslie matrices, I estimated the intrinsic daily rate of increase
($r$) in aphid populations in the lab as $r = \log(\lambda)$, where $\lambda$ is the
dominant eigenvector of the matrix.
Thus I have fast and slow estimates of population growth to use as prior information
about our population-growth assays.


```{r load_leslies}
fast <- clonewars::leslie %>% 
    .[["fast"]] %>% 
    eigen() %>% 
    .[["values"]] %>% 
    .[1] %>% 
    Re() %>% 
    log()
slow <- clonewars::leslie %>% 
    .[["slow"]] %>% 
    eigen() %>% 
    .[["values"]] %>% 
    .[1] %>% 
    Re() %>% 
    log()
cat(sprintf("fast = %.4g\n", fast))
cat(sprintf("slow = %.4g\n", slow))
```



```{r define_R_priors}
# mean and SD  of the normal distribution that generates rho values
#   (rho = among-line mean of the log-transformed growth rates)
theta[3] <- c(fast, slow) %>% 
    log() %>% 
    mean() %>% 
    signif(4)
theta[4] <- c(fast, slow) %>%
    log() %>% 
    sd() %>% 
    `*`(., 10) %>% 
    signif(4)

# meanlog and sdlog parameters for the distribution that generates
#   sigma_rho values
#   (sigma_rho = among-line standard deviation of the log-transformed growth rates)
theta[5] <- c(fast, slow) %>% 
    log() %>% 
    sd() %>% 
    signif(4)
theta[6] <- 1.0
```


I also simulated some data with $r = \{ 0.25, 0.5, 0.75, 1.25 \}$ to compare the 
simulations to the preliminary data.
Below, "rX" indicates a panel of simulated data with $r$ set to the number X.
The others are the preliminary data.
From these simulations, values of $r > 0.5$ seem pretty unlikely.


```{r load_prior2, fig.height=6}
sim_R <- function(df_, R_, alpha_ = 1/2000) {
    add_row(df_, 
            line = paste0("r", R_), rep = rep(1:5, each=15), 
            date = rep(1:15, 5) + 3,
            X = sim_lines(R = R_, alpha = alpha_, n_reps = 5,
                          nobs_ts = rep(15, 5), sigma_process = theta[1]) %>% 
                as.numeric())
}

load_prior_data() %>% 
    filter(!is.na(line)) %>% 
    sim_R(0.25) %>% 
    sim_R(0.5) %>% 
    sim_R(0.75) %>% 
    sim_R(1) %>% 
    sim_R(1.25) %>% 
    mutate(rep = factor(rep)) %>% 
    ggplot(aes(date, X)) +
    geom_line(aes(color = rep)) +
    facet_wrap(~ line, nrow = 3) +
    scale_color_brewer(palette = "Dark2", guide = FALSE)
```





For sampling $\rho$, I used a mean ($\theta_3$ parameter) of `mean(log(c(fast, slow)))`,
$`r theta[3]`$.
For the standard deviation of $\rho$ (NOT the among-line SD, rather $\theta_4$)
I used `sd(log(c(fast, slow))) * 10`, $`r theta[4]`$.
I multiplied by 10 to add extra uncertainty because of the limited number of lines
from which I derived my priors.
In the plot below, I've exponentiated the x-axis so that it displays the values of
$r$ that would result.


```{r mean_theta_distr}
compare_priors(dlnorm_, theta[3], theta[4], xlim = c(0, 2)) +
    geom_vline(xintercept = exp(theta[3])) +
    ggtitle(expression(plain(exp)(rho %~% plain(N)(
        theta[3] * "," ~ theta[4])))) +
    # coord_cartesian(ylim = c(0, 0.4 / theta[4])) +
    NULL
```


For sampling $\sigma_\rho$ (the among-line SD of $\log(r)$),
I used `sd(log(c(fast, slow)))` ($`r theta[5]`$) for the mean ($\theta_5$ parameter)
and $`r theta[6]`$ for the SD ($\theta_6$ parameter).
The latter was chosen to indicate even more uncertainty in $\sigma_\rho$ than in
$\rho$.

```{r s_theta_distr}
compare_priors("normal", theta[5], theta[6], xlim = c(0, 2)) +
    geom_vline(xintercept = theta[5]) +
    ggtitle(expression(sigma[rho] %~% plain("N")(theta[5] * "," ~ theta[6]))) +
    coord_cartesian(ylim = c(0, 0.4 / theta[6])) +
    NULL
```





## Density dependence

Logit-transformed density dependences ($\text{logit}(\alpha)$) were sampled based
on three parameters:
overall mean ($\phi \sim \text{N}(\theta_7, ~ \theta_8^{~2})$),
among-line SD
($\sigma_{\phi a} \sim \text{N}(\theta_9, ~ \theta_{10}^{~2}) \texttt{T[0,]}$),
and
within-line SD
($\sigma_{\phi w} \sim \text{N}(\theta_{11}, ~ \theta_{12}^{~2}) \texttt{T[0,]}$).

For density dependence prior information, I used data from
preliminary population-growth assays that used the same methods that we're using.
We conducted these assays on 4 aphid lines that we no longer maintain in the lab
and won't be using for our analyses or cage experiments.

If we look at the deterministic portion of our model...

$$
X_{t+1} = X_t + r \left( 1 - \alpha ~ \text{e}^{X_t} \right)
$$
... we can see that $X_{t+1} = X_t$ when $\alpha = 1 / \exp(X_t) = 1 / N_t$.
Because each repetition is run until the plant dies and populations crash,
I'll assume that for each repetition, our estimate of $\alpha$ is $1 / \max(N_t)$.

Here is how I coded it:

```{r load_prior_data_alpha, echo = TRUE}
prior_df <- load_prior_data() %>% 
    filter(!is.na(line)) %>% 
    group_by(line, rep) %>% 
    summarize(alpha = 1 / max(N)) %>% 
    ungroup()
prior_df
```
```{r logit_funs_and_application}
logit <- function(p) log(p / (1-p))
inv_logit <- function(x) 1 / (1 + exp(-x))
prior_df <- prior_df %>% 
    mutate(logit_alpha = logit(alpha))
```



```{r define_alpha_priors}
# mean and standard deviations of the normal distribution that generates phi values
#   (phi = among-line mean of the logit-transformed density dependences)
theta[7] <- prior_df %>% 
    group_by(line) %>% 
    summarize(logit_alpha = mean(logit_alpha)) %>% 
    ungroup() %>% 
    summarize(logit_alpha = mean(logit_alpha)) %>% 
    .[["logit_alpha"]] %>% 
    signif(4)
theta[8] <- prior_df %>% 
    group_by(line) %>% 
    summarize(logit_alpha = mean(logit_alpha)) %>% 
    ungroup() %>% 
    summarize(logit_alpha = sd(logit_alpha)) %>% 
    .[["logit_alpha"]] %>% 
    `*`(., 10) %>%
    signif(4)

# - $\theta_9$: mean of the normal distribution that generates $\sigma_{\phi a}$ values
# - $\theta_{10}$: sd of the normal distribution that generates $\sigma_{\phi a}$ values
# - $\theta_{11}$: mean of the normal distribution that generates $\sigma_{\phi w}$ values
# - $\theta_{12}$: sd of the normal distribution that generates $\sigma_{\phi w}$ values

theta[9] <- prior_df %>% 
    group_by(line) %>% 
    summarize(logit_alpha = mean(logit_alpha)) %>% 
    ungroup() %>% 
    summarize(logit_alpha = sd(logit_alpha)) %>% 
    .[["logit_alpha"]] %>% 
    signif(4)
theta[10] <- 1

theta[11] <- prior_df %>%
    group_by(line) %>% 
    summarize(logit_alpha = sd(logit_alpha)) %>% 
    ungroup() %>% 
    summarize(logit_alpha = mean(logit_alpha)) %>%
    .[["logit_alpha"]] %>%
    signif(4)
theta[12] <- prior_df %>%
    group_by(line) %>%
    summarize(logit_alpha = sd(logit_alpha)) %>% 
    ungroup() %>%
    summarize(logit_alpha = sd(logit_alpha)) %>%
    .[["logit_alpha"]] %>%
    `*`(., 2) %>%
    signif(4)
```


### Overall mean

For sampling $\phi$, I used the mean $\text{logit}(\alpha)$ across lines,
$`r theta[7]`$, as my prior for $\theta_7$.
I multiplied the among-line SD of $\text{logit}(\alpha)$ by 10
(resulting in $`r theta[8]`$)
for my prior on $\theta_8$ to decrease my certainty in estimates.
For the plot below, I inverse-logit transformed the x-axis to show the resulting $\alpha$
values from these priors.
It still has pretty low densities above 0.5, which is reasonable because that
would indicate a "carrying capacity" of < 2.

```{r alpha_overall_mean_plot}
logit_dlnorm <- function(p, location, scale) {
    dnorm(logit(p), location, scale)
}
compare_priors(logit_dlnorm, theta[7], theta[8], xlim = c(0, 1)) +
    geom_vline(xintercept = inv_logit(theta[7]), linetype = 2) +
    coord_cartesian(ylim = c(0, 0.4 / theta[8])) +
    ggtitle(expression({plain("logit")^{-1}}(
        phi %~% plain(N)(theta[7] * "," ~ theta[8]))))
```


### Among-line SD

For the distribution of $\sigma_{\phi a}$ values, I used the SD for among-line 
mean $\text{logit}(\alpha)$ ($`r theta[9]`$) for the mean (parameter $\theta_9$), and
$`r theta[10]`$ for the SD (parameter $\theta_{10}$).
The latter was chosen simply because I'm not very sure of what it should be, and 
this value results in a pretty flat prior distribution.


```{r alpha_line_means_plot}
compare_priors("normal", theta[9], theta[10], xlim = c(0, 2)) +
    geom_vline(xintercept = theta[9]) +
    ggtitle(expression(sigma[phi * a] %~% plain("N")(theta[9] * "," ~ theta[10]))) +
    coord_cartesian(ylim = c(0, 0.4 / theta[10])) +
    NULL
```



### Within-line SD

For sampling $\sigma_{\phi w}$,
I used the mean of within-line SDs, $`r theta[11]`$, for $\theta_{11}$.
I multiplied the SD of within-line SDs by 10, resulting in $`r theta[12]`$,
for $\theta_{12}$.
This results in the following weakly informative prior:


```{r alpha_within_line_sd_plot}
compare_priors("normal", theta[11], theta[12], xlim = c(0, theta[11] + 2 * theta[12])) +
    geom_vline(xintercept = theta[11]) +
    ggtitle(expression(sigma[phi * w] %~% plain("N")(theta[11] * "," ~ theta[12]))) +
    coord_cartesian(ylim = c(0, 0.4 / theta[12])) +
    NULL
```




# Final priors

```{r priors_table}
data_frame(
    par = c(
        "$\\theta_{1}$",
        "$\\theta_{2}$",
        "$\\theta_{3}$",
        "$\\theta_{4}$",
        "$\\theta_{5}$",
        "$\\theta_{6}$",
        "$\\theta_{7}$",
        "$\\theta_{8}$",
        "$\\theta_{9}$",
        "$\\theta_{10}$",
        "$\\theta_{11}$",
        "$\\theta_{12}$"
    ),
    value = sprintf("$%.5f$", theta),
    `description${}^{†}$` = c(
        "mean for $\\sigma_\\varepsilon$",  # 1
        "SD for $\\sigma_\\varepsilon$",  # 2
        "mean for $\\rho$",  # 3
        "SD for $\\rho$",  # 4
        "mean for $\\sigma_\\rho$",  # 5
        "SD for $\\sigma_\\rho$",  # 6
        "mean for $\\phi$",  # 7
        "SD for $\\phi$",  # 8
        "mean for $\\sigma_{\\phi a}$",  # 9
        "SD for $\\sigma_{\\phi a}$",  # 10
        "mean for $\\sigma_{\\phi w}$",  # 11
        "SD for $\\sigma_{\\phi w}$"  # 12
    )
) %>% 
    knitr::kable(format = "html", booktabs = TRUE, escape = FALSE,
                 align = c("l", "r", "l"))
```
$†$ For descriptions, "mean for $X$" indicates the mean for the distribution that generates
$X$ values.
